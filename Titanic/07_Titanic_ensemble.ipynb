{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498c5457",
   "metadata": {},
   "source": [
    "6. Ансамбли\n",
    "    1. Усреднение\n",
    "    2. Voting\n",
    "    3. Stacking через линейную регрессию и Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb39b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "461a7bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фичи 14 Строки 891\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(config.CONFIG['paths']['train_with_folds_fe'])\n",
    "TARGET_COL = config.CONFIG['validation']['target_column']\n",
    "N_SPLITS = config.CONFIG['validation']['n_splits']\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in [TARGET_COL, 'fold'] and pd.api.types.is_numeric_dtype(df[c])]\n",
    "print('Фичи', len(feature_cols), 'Строки', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686788d",
   "metadata": {},
   "source": [
    "# Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e12d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv_oof(model_class, model_params, df, target_col=TARGET_COL, n_splits=N_SPLITS):\n",
    "    oof_preds = np.zeros(len(df))\n",
    "    oof_proba = np.zeros(len(df))\n",
    "    scores = []\n",
    "    for fold in range(n_splits):\n",
    "        train_mask = df['fold'] != fold\n",
    "        val_mask = df['fold'] == fold\n",
    "        X_train = df.loc[train_mask, feature_cols]\n",
    "        y_train = df.loc[train_mask, target_col]\n",
    "        X_val = df.loc[val_mask, feature_cols]\n",
    "        y_val = df.loc[val_mask, target_col]\n",
    "\n",
    "        model = model_class(**model_params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        oof_preds[val_mask] = model.predict(X_val)\n",
    "        oof_proba[val_mask] = model.predict_proba(X_val)[:, 1]\n",
    "        scores.append(accuracy_score(y_val, oof_preds[val_mask]))\n",
    "\n",
    "    return oof_preds, oof_proba, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34b7ab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg: 0.8081 +- 0.0114\n",
      "RF: 0.8317 +- 0.0122\n",
      "XGB: 0.8024 +- 0.0325\n",
      "CatBoost: 0.8339 +- 0.0150\n"
     ]
    }
   ],
   "source": [
    "params_lr = {'max_iter': 3000, 'random_state': 42}\n",
    "params_rf = {'n_estimators': 200, 'max_depth': 5, 'random_state': 42}\n",
    "params_xgb = {'n_estimators': 200, 'max_depth': 4, 'random_state': 42, 'eval_metric': 'logloss'}\n",
    "params_cat = {'iterations': 200, 'depth': 4, 'verbose': 0, 'random_state': 42}\n",
    "\n",
    "oof_probas = {}\n",
    "scores_per_model = {}\n",
    "\n",
    "oof_preds_lr, oof_proba_lr, scores_lr = run_cv_oof(LogisticRegression, params_lr, df)\n",
    "oof_probas['lr'] = oof_proba_lr\n",
    "scores_per_model['LogReg'] = (np.mean(scores_lr), np.std(scores_lr))\n",
    "\n",
    "oof_preds_rf, oof_proba_rf, scores_rf = run_cv_oof(RandomForestClassifier, params_rf, df)\n",
    "oof_probas['rf'] = oof_proba_rf\n",
    "scores_per_model['RF'] = (np.mean(scores_rf), np.std(scores_rf))\n",
    "\n",
    "oof_preds_xgb, oof_proba_xgb, scores_xgb = run_cv_oof(XGBClassifier, params_xgb, df)\n",
    "oof_probas['xgb'] = oof_proba_xgb\n",
    "scores_per_model['XGB'] = (np.mean(scores_xgb), np.std(scores_xgb))\n",
    "\n",
    "oof_preds_cat, oof_proba_cat, scores_cat = run_cv_oof(CatBoostClassifier, params_cat, df)\n",
    "oof_probas['cat'] = oof_proba_cat\n",
    "scores_per_model['CatBoost'] = (np.mean(scores_cat), np.std(scores_cat))\n",
    "\n",
    "for name, (m, s) in scores_per_model.items():\n",
    "    print(f'{name}: {m:.4f} +- {s:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881cc495",
   "metadata": {},
   "source": [
    "# Усреднение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c9b96d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Усреднение OOF accuracy: 0.8305\n"
     ]
    }
   ],
   "source": [
    "proba_avg = (oof_proba_lr + oof_proba_rf + oof_proba_xgb + oof_proba_cat) / 4\n",
    "pred_avg = (proba_avg >= 0.5).astype(int)\n",
    "acc_avg = accuracy_score(df[TARGET_COL], pred_avg)\n",
    "print('Усреднение OOF accuracy:', round(acc_avg, 4))\n",
    "scores_per_model['Averaging'] = (acc_avg, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a64fa",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2eeb49b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting OOF mean accuracy: 0.8305 +- 0.0241\n"
     ]
    }
   ],
   "source": [
    "estimators_voting = [\n",
    "    ('lr', LogisticRegression(**params_lr)),\n",
    "    ('rf', RandomForestClassifier(**params_rf)),\n",
    "    ('xgb', XGBClassifier(**params_xgb)),\n",
    "    ('cat', CatBoostClassifier(**params_cat)),\n",
    "]\n",
    "voting = VotingClassifier(estimators=estimators_voting, voting='soft')\n",
    "\n",
    "_, _, scores_vote = run_cv_oof(VotingClassifier, {'estimators': estimators_voting, 'voting': 'soft'}, df)\n",
    "scores_per_model['Voting'] = (np.mean(scores_vote), np.std(scores_vote))\n",
    "print('Voting OOF mean accuracy:', round(np.mean(scores_vote), 4), '+-', round(np.std(scores_vote), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f90734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   method  mean_acc  std_acc\n",
      " CatBoost  0.833890 0.014952\n",
      "       RF  0.831655 0.012225\n",
      "Averaging  0.830527 0.000000\n",
      "   Voting  0.830494 0.024134\n",
      "   LogReg  0.808085 0.011380\n",
      "      XGB  0.802410 0.032515\n",
      "Сохранено: C:\\newTry2\\classicMLpractice\\ProjectKaggle\\checkpoints\\ensemble_results.csv\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame([\n",
    "    {'method': name, 'mean_acc': m, 'std_acc': s}\n",
    "    for name, (m, s) in scores_per_model.items()\n",
    "]).sort_values('mean_acc', ascending=False)\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "ensemble_path = config.CONFIG['paths'].get('ensemble_results', config.CONFIG['paths']['checkpoint_dir'] / 'ensemble_results.csv')\n",
    "results.rename(columns={'method': 'model', 'mean_acc': 'mean_accuracy', 'std_acc': 'std_accuracy'}).to_csv(ensemble_path, index=False)\n",
    "print('Сохранено:', ensemble_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
